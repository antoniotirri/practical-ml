<html>

<head>
<title>Coursera Practical Machine Learning Project Work</title>
</head>

<body>

<b>GENERAL INFORMATION</b>
<p>
The purpose of this project is to classify a set of exercise movements.
There are four classes (A,B,C,D,E) corresponding to the labels "Correct","Throwing elbows to the front", "lifting dumbbell only halfway", "lowering dumbbell only halfaway", "throwing hips to the front".
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 
There are two datasets. A training dataset  
<!--begin.rcode
# pml_training.csv
end.rcode-->
and a test dataset
<!--begin.rcode
# pml_testing.csv
end.rcode-->
</p>

First of all let's load the packages that wil lbe used and let's set a seed for reproducibility

<!--begin.rcode
library(caret)
library(randomForest)
set.seed(28071984)
end.rcode-->


<b>DATA EXPLORATION</b>
<p>Looking at the pml_training.csv, it is possible to see that there are two kinds of missing values: "NA" values and “#DIV/0!”. Moreover, all the values are separated by a comma.
Only the variables that contains the names 
<!--begin.rcode
# _arm _belt _dumbbell _forearm
end.rcode-->      

are related to sensor values. The other ones are information not useful for the prediction purpose. The Classe variable is the outcome we want to predict.
</p>

<b>DATA LOADING AND CLEANING</b>
<p>First of all we load the dataset</p>

<!--begin.rcode
pml_training = read.csv("pml-training.csv", header = TRUE, sep = ",", na.strings = c("NA", "#DIV/0!"))
end.rcode-->
<p>Then we use only the sensor data related variables together with the classe variable</p>
<!--begin.rcode
colOfInterest = grep(pattern = "_arm|_belt|_dumbbell|_forearm", names(pml_training))
columnsOfInterestTraining=c(colOfInterest,dim(pml_training)[2])
train=pml_training[,columnsOfInterestTraining]
end.rcode-->

<p>If we perform the command

<!--begin.rcode
colSums(is.na(train))
end.rcode-->
we can see that there are some variables with about 19200 NA values in the observations. Since these variables are not useful for the prediction purpose, we remove them from the dataset.
</p>

<!--begin.rcode
tr=train[,-(which(colSums(is.na(train)) > 19200))]
end.rcode-->

<p>Then we name the Class variable as a factor</p>
<!--begin.rcode
tr$classe=factor(tr$classe)
end.rcode-->

<p>After that, let's create training (70%) and testing (30%) set from the data we have. We will use the testing set to calculate an estimation of the out-of-sample error.</p>
<!--begin.rcode
inTrain=createDataPartition(y=tr$classe,p=0.7,list=F)
training=tr[inTrain,]
testing=tr[-inTrain,]
end.rcode-->
<b>PREDICTION MODEL AND OOB ERROR</b>
<p> For the creation of the prediction model, we use the Random Forest function </p>
<!--begin.rcode
modFit=randomForest(classe~., data=tr)
modFit
end.rcode-->
<p>The estimate of OOB error is really low (0.28%)</p>

<b>PREDICTING NEW VALUES</b>
<p>In order to predict the classe label for the testing values, we perform this command</p>
<!--begin.rcode
pred=predict(modFit,testing)
end.rcode-->
<p>The related confusion Matrix is:</p>
<!--begin.rcode
confusionMatrix(pred,testing$classe)
end.rcode-->

<p>The Overall Statistics section (Accuracy, Kappa) shows the out-of-sample error rate. In particular, in this case Accuracy is 100%.

Using the dataset pml_testing.csv as new data, it is possible to see that all the cases were correctly predicted.
</body>
</html>
